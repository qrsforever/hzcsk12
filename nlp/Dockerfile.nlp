FROM hzcsai_com/hzcsk12-base

LABEL maintainer="k12nlp@hzcsai.com"

ARG VENDOR
ARG PROJECT
ARG REPOSITORY
ARG TAG
ARG DATE
ARG VERSION
ARG URL
ARG COMMIT
ARG BRANCH
ARG PORT

LABEL org.label-schema.schema-version="1.0" \
      org.label-schema.build-date=$DATE \
      org.label-schema.name=$REPOSITORY \
      org.label-schema.description="NLP Backend" \
      org.label-schema.url=https://www.hzcsai.com/index.php?r=front \
      org.label-schema.vcs-url=$URL \
      org.label-schema.vcs-ref=$COMMIT \
      org.label-schema.vcs-branch=$BRANCH \
      org.label-schema.vendor=$VENDOR \
      org.label-schema.version=$VERSION \
      org.label-schema.docker.cmd="docker run -it --rm --name $PROJECT \
--network host --hostname $PROJECT --entrypoint /bin/bash \
--runtime nvidia --shm-size=2g --ulimit memlock=-1 --ulimit stack=67108864 \
--volume /data:/data $REPOSITORY:$TAG"

COPY requirements.txt .
RUN pip install -i https://mirrors.aliyun.com/pypi/simple/ -r requirements.txt

COPY app app/
COPY scripts/ scripts/
COPY allennlp/ allennlp/
COPY setup.py setup.py

RUN pip install --editable .

# Compile EVALB - required for parsing evaluation.
# EVALB produces scary looking c-level output which we don't
# care about, so we redirect the output to /dev/null.
RUN cd allennlp/tools/EVALB && make &> /dev/null && cd ../../../

# Caching models when building the image makes a dockerized server start up faster, but is slow for
# running tests and things, so we skip it by default.
ARG CACHE_MODELS=false
RUN ./scripts/cache_models.py


# Optional argument to set an environment variable with the Git SHA
ARG SOURCE_COMMIT
ENV ALLENNLP_SOURCE_COMMIT $SOURCE_COMMIT

# Copy wrapper script to allow beaker to run resumable training workloads.
COPY scripts/ai2-internal/resumable_train.sh /hzcsk12/app

EXPOSE 8000
CMD ["/bin/bash"]
